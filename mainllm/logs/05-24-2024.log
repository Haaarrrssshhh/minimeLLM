2024-05-24 04:17:17 HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-05-24 04:17:17 Query: tell me about a project where you used BERT
2024-05-24 04:17:17 Response: I cannot share this information with you!
2024-05-24 04:18:06 /Users/harshzota/Desktop/Dev/minimeLLM/mainllm/views.py changed, reloading.
2024-05-24 04:18:20 HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-05-24 04:18:20 Query: tell me about your project using BERT
2024-05-24 04:18:20 Response: I cannot share this information with you!
2024-05-24 04:18:20 Retrived Info: [['Although I have done many projects, I would like to highlight a few main ones, which also defines my journey in LLM and AI\n\nMyRecipe\nThe AI-Powered Recipe Recommendation System project, conducted from March to April 2024, developed a system that suggests recipes based on available ingredients using natural language processing (NLP) and machine learning techniques. The project involved several steps: collecting data from sources like Kaggle and AllRecipes, preprocessing the data to standardize ingredients, and performing feature engineering using techniques such as TF-IDF vectorization and cosine similarity. The model was developed using collaborative and content-based filtering approaches, with a hybrid model improving recommendation accuracy. The system was evaluated using metrics like precision and recall, and user feedback was incorporated for continuous improvement.\n\nThe final system was deployed as a web application using Flask, with containerization via Docker to ensure scalability and reliability. The application features a user-friendly interface where users can input their ingredients to receive recipe recommendations. The code provided includes steps for preprocessing, model training, and deployment, demonstrating the project\'s comprehensive approach to creating an effective recipe recommendation system that enhances cooking experiences and reduces food waste.\n\nMiniMe\nThe "MiniME - Personalized Chatbot for Self-Introduction" project involves developing a chatbot that uses natural language processing (NLP) to provide detailed and accurate responses about oneself. The process begins with data collection, including curating personal information and extracting data from public profiles. After preprocessing the text data, which includes cleaning, tokenizing, and normalizing, the project leverages word embeddings and context-aware embeddings using models like BERT or GPT-3. These embeddings represent text data in a high-dimensional vector space. A pre-trained language model is fine-tuned on the curated dataset to generate personalized responses.\n\nThe model development phase involves selecting and fine-tuning a suitable transformer model, followed by rigorous evaluation using metrics like perplexity and BLEU scores, along with user feedback. The chatbot is deployed using a Flask web application, with RESTful APIs handling user queries and Docker ensuring scalability. This project effectively combines NLP techniques and machine learning to create a personalized, interactive chatbot for self-introduction, enhancing user engagement and providing accurate information.\n\nSentinex AI - The "SentixAI - Sentiment Tracker for Personal Notes" project involved developing a sentiment analysis tool integrated into a personal notes application using natural language processing (NLP) and a fine-tuned BERT model. The project began with collecting and preprocessing personal notes and sentiment-labeled datasets, followed by fine-tuning a pre-trained BERT model to achieve 80% accuracy in sentiment classification. The sentiment tracker was implemented into the application to analyze user notes in real-time, providing sentiment scores (positive, negative, or neutral). \n\nThe system\'s deployment involved creating a Flask API and using Docker for scalability. The impact of the sentiment tracker was quantified through user surveys, revealing a 30% increase in self-awareness among users, who reported gaining valuable insights into their emotional well-being. This project effectively combined advanced NLP techniques and user feedback to enhance self-awareness and emotional intelligence.\n\n', ' I have worked at multiple companies , from a young age. I began working as a Marketing Person and then I did my first tech job at Sahu Technologiesas a web developer intern, then at Skinzy Solutions as a Machine Learning intern, then at Tyrannix Pvt Ltd as a software engineer and currently at frugal innovation hub at scu as a software developer. The project I am most proud of the most recent one I built. My current coursework has been towards all latest technology today including ML, DL, AI, NLP. I made a project in this domain called MiniMe. For this although it took only 1 month to actually build it , it has come as a byproduct and an enhancement of my previous projects. What it does is that it gives you an introduction about me and tells you about me. It is a personalized chatbot as if you were talking to me. It is meaningful to me as in todays date and time where everything is so AI driven and powered I too have now had a solid step in the same and I see myself goingon and ahead.', 'I have made 2 major publications \nFirst was  "A Comparative Study of Widely Used Image Detection Algorithms" , is where I began my journey in the field of AI.\nThe paper "A Comparative Study of Widely Used Image Detection Algorithms" by Harsh Zota and Manoj Dhande examines six prevalent image detection algorithms: YOLO (You Only Look Once), HOG (Histogram Oriented Gradients), Fast R-CNN (Fast Region-Based Convolutional Neural Network), R-CNN (Region-Based Convolutional Neural Network), R-FCN (Region-Based Fully Convolutional Network), and SSD (Single Shot Detector). Each algorithm is assessed for its effectiveness in various scenarios based on speed, accuracy, and complexity. YOLO is highlighted for its real-time object detection capability, HOG for its detailed feature extraction, Fast R-CNN and R-CNN for their regional proposal methods, R-FCN for detecting minute details with high speed and accuracy, and SSD for handling low-resolution images effectively. The study aims to guide readers in selecting the most suitable algorithm for their specific project requirements by detailing the pros and cons of each method and providing use-case scenarios where each algorithm excels.\n\nAnother paper I wrote was\n"A Mobile Application for Handwritten Text Recognition" by Ved Bhanushali, Harsh Zota, Krimesh Shah, and Dr. Manimala Mahato focuses on developing a mobile application to convert handwritten documents into text. The project aims to address challenges faced by educators during the pandemic, such as grading handwritten assignments submitted as PDFs. Utilizing algorithms like CNN, RNN, and CTC, the application processes scanned or uploaded images of handwritten text, pre-processes them to improve clarity, and segments the text into characters and words for recognition. The model, trained on the IAM dataset, is integrated into an Android application, enabling offline text recognition with high accuracy. The paper also reviews relevant literature and details the methodology, including data collection, preprocessing, model training, and deployment. The developed application aims to streamline the process of converting handwritten notes to digital text, facilitating easier storage, editing, and grading.\nIt was also my final year project.', 'HighSchool - K.C College, Mumbai India, Grade A , Distinction . June 2015-June 2017\nUndergraduate - University of Mumbai,Bachelor of Engineering, Majors in Computer Science. GPA - 3.56. July 2017 - June 2021\nCourseWork - Applied Mathematics - I,II,III,IV. , Applied Physics , Applied Chemistry, Object Oriented Programming Methodology(JAVA). Computer Organization Architecture. Database management Systems. Data Structures and Algorithms, Advance Algorithm, Software Engineering, Data Warehousing and Mining, Machine Learning, Artificial Intelligence and Soft Computing, Human Machine INteraction, Distributed Systems, Cloud Computing, Big Data and Analytics,\nGraduate School - Santa Clara University, Masters In Computer Science & Engineering, GPA - 3.175 , September 2023 - June 2025.\nCoursework - Computer Architecture, Design and Analysis of algorithms, Advance Operating Systems, Computer Networks, Machine Learning, Object Oriented Analysis Design and Programming. \n', 'Sahu Technologies - Web Developer Intern. Jan 2019 - Feb 2019.\nI worked as a Web Developer intern , here I was introduced to web technologies for the first time. This was like a learning experience and also delivered on the ongoing product.  As a junior web developer, I actively developed responsive web pages. Coordinated with the team, understood requirements. • Executed Web Development with HTML, CSS3, BootStrap and ReactJs.\n\nSkinzy Solutions Pvt Ltd - Machine Learning Intern, Feb 2020 - December 2020.\nI worked as a Machine Learning Intern, the sole one on a team of 10 people. My primary responsibility over the course of the first 6 months was to research different object classification algorithms. I researched multiple research papers, went through multiple medium blogs to figure out the best model. After I had a set of models I needed , I further had to figure out a pipeline of how to first preprocess my data and then also train the algorithm and save the model. In the extended duration of furthur 5 months , I Engineered and deployed a cutting-edge machine learning model on AWS, leveraging SageMaker and EC2 instances, achieving a 20% boost in predictive accuracy through hyperparameter tuning and feature engineering. Collaborated seamlessly across teams, utilizing AWS services such as S3 for scalable storage, Lambda for serverless computing, and Step Functions for streamlined workflow automation, ensuring efficient end-to-end machine learning product pipelines.\n\nTyrannix Pvt Ltd - Software Engineer , July 2021 - April 2022, Mumbai , India.\nI worked as a Software Engineer , with prior knowledge of different machine learning algorithms and also with basic knowledge of web development from my previous internships, I began working on a similar project I had done, but on a much larger scale. I was given a set of 8000 samples to work on. I worked on preprocessing the data , with different things to work on the data with. I increased the size of the image, scaled it, and changed all to grayscale. In the end I would end up with over 35000 preprocessed images to work on. Since I had a very huge database I chose to work with Yolov5 and gained an accuracy of over 95% on an average. With that I then wrote scripts to automate the testing of the trained model and also improved the accuracy of the model with continuous iterations.\nAnother key project I worked on was making the complete UI of a gaming application, which catered to over 500000 users a day and over 50000 concurrent users. I used component composition with hooks and also state management with reducers. For data management I used React Redux. Then came HPD , where I implemented all my learnt skills frontend and backend using NodeJs.  Here I used entity pattern development. Led development of a Microservices-based project for Scientific Games, a global client. Analyzed requirements, engineered the architecture, Deployed on AWS using CloudFront, S3, EC2, Redis, EBS, ECS and Route 53 to ensure a robust and scalable solution. Developed websockets and used redis to integrate third party odds-API for constant microsecond changes of odds, implemented cron jobs for checking status of placed bets, processed data in real time, used Tableau for data visualization. Deployed trained model to EC2 instance with CI/CD pipelining, ensured load balancing with Nginx to provide a long term and scalable solution, collaborated with cross-functional teams to deploy a computer vision system for quality control.\nSpearheaded development of RealX, integrated national ID verification API, gRPC architecture , API encryption and TOTP service for secure communication, integrated Razorpay (Web/Android/iOS) for payments, increasing successful payments by 20%. Managed image and video storage with AWS S3, mongoDB, integrated third party blockchain API, integrated bank payment gateways for secure transactions, designed an algorithm to rate properties on factors like location, market trends and demand. Led the end-to-end development of Pupperazy using NodeJs, ReactJs and MongoDb, integrated Google developer API, enabled geolocation based services to manage services and appointments in a region which in turn increased sales and revenue by 45%. Applied machine learning techniques to optimize appointment booking, resulting in 20% improvement in revenue, integrated SMTP for regular updates on user appointments, integrated websocket to provide live updates on status of user’s appointment\n\n\n\n\nFrugal Innovation Hub (SCU) - Software Engineer, October 2023 - Present , Santa Clara, CA, USA\nI work here as a Software Engineer. Although being here for a short period of time, I have been able to contribute a lot due to my vast experience in the past. I worked on Equation 2 Success , which is a project for students to report bullying or any such cases in school. I was responsible for refactoring the whole codebase to a repository development pattern , which is really useful for a plug-n-play kind of development. Among other things I was also responsible for deploying the backend on AWS EC2 server for seamless user experience. For easy and seamless development I also employed CI/CD pipelines.']]
2024-05-24 04:18:43 /Users/harshzota/Desktop/Dev/minimeLLM/mainllm/views.py changed, reloading.
2024-05-24 04:19:13 HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-05-24 04:19:13 Query: tell me about your project myrecipe
2024-05-24 04:19:13 Response: I have developed a project called MyRecipe, an AI-Powered Recipe Recommendation System that suggests recipes based on available ingredients using NLP and machine learning techniques. The system involves collecting data, preprocessing ingredients, and using collaborative and content-based filtering approaches for accurate recommendations. The final system is deployed as a web application with a user-friendly interface for inputting ingredients and receiving recipe suggestions.
2024-05-24 04:31:30 /Users/harshzota/Desktop/Dev/minimeLLM/minime/settings.py changed, reloading.
2024-05-24 04:32:53 /Users/harshzota/Desktop/Dev/minimeLLM/minime/settings.py changed, reloading.
